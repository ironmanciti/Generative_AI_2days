{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e2e08433",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2e08433",
        "outputId": "2e142fb7-8451-447c-be7c-78ffec064b9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.7.0-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.7/224.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Collecting typing-extensions<5,>=4.7 (from openai)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: typing-extensions, h11, httpcore, httpx, openai\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 openai-1.7.0 typing-extensions-4.9.0\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -q openai\n",
        "!pip install -q python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "42ca44b1",
      "metadata": {
        "id": "42ca44b1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "import sys\n",
        "sys.path.append('./')\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv()) # read local .env file\n",
        "\n",
        "openai.api_key  = os.environ['OPENAI_API_KEY']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22a511e7",
      "metadata": {
        "id": "22a511e7"
      },
      "source": [
        "# Method 1 - openai library 이용\n",
        "## role of the messages author\n",
        "\n",
        "OpenAI API에서 각 메시지의 저자(`author`) 역할은 다음과 같은 의미를 가집니다:\n",
        "\n",
        "1. **system**: 시스템 관련 메시지나 지침. 예를 들면, 어시스턴트에게 특정 작업을 수행하는 방법에 대한 지침을 제공하는 경우에 사용됩니다. 이러한 지침은 어시스턴트의 응답을 안내하거나 제한할 수 있습니다.\n",
        "\n",
        "2. **user**: 사용자가 입력한 메시지. 대체로 사용자의 질문, 요청, 지침 등을 나타냅니다.\n",
        "\n",
        "3. **assistant**: 어시스턴트(즉, 모델)가 반환하는 응답 또는 메시지. 사용자의 질문에 대한 답변, 제안, 설명 등을 포함할 수 있습니다.\n",
        "\n",
        "이러한 역할은 대화형 세션에서 메시지의 발신자와 의도를 구별하는 데 도움을 줍니다. API는 이 정보를 사용하여 적절한 방식으로 반응하거나 응답합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "6e5af24f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e5af24f",
        "outputId": "93b97ade-2c68-4a94-8585-36a413479825"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content='Hello! How can I assist you today?', role='assistant', function_call=None, tool_calls=None)\n"
          ]
        }
      ],
      "source": [
        "completion = openai.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Hello!\"}\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "a1fefb54",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1fefb54",
        "outputId": "6ebc0f0a-f3e0-4d94-fe6c-2e39ef6ce932"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User : 안녕\n",
            "ChatGPT: 안녕하세요! 도움이 필요하신가요?\n",
            "User : 서울역에서 남산에 가는 방법을 알려줘\n",
            "ChatGPT: 서울역에서 남산에 가는 가장 간편한 방법은 지하철을 이용하는 것입니다. 아래는 세 가지의 경로 중 가장 흔히 사용되는 방법입니다:\n",
            "\n",
            "1. 지하철 4호선: 서울역에서 4호선으로 환승합니다. 시청역에서 1번 출구로 나와 남산으로 가는 계단을 찾아 올라가면 됩니다.\n",
            "\n",
            "2. 지하철 1호선: 서울역에서 1호선으로 환승합니다. 남영역에서 하차하여 저상버스 02 또는 03을 타고 남산도서관 정류장에서 내리면 됩니다.\n",
            "\n",
            "3. 지하철 2호선: 서울역에서 2호선으로 환승합니다. 시청역에서 1번 출구로 나와서 남산케이블카를 이용할 수도 있습니다. 혹은 시청역에서 도보로 10분 정도 걸어가면 남산에 도착합니다.\n",
            "\n",
            "여행하기 전에 대중교통 앱이나 웹사이트를 확인해 정확한 노선과 시간표를 확인하는 것이 좋습니다. 즐거운 시간 보내세요!\n",
            "User : stop\n"
          ]
        }
      ],
      "source": [
        "# assistant 에 대한 지침이 되는 context 정보를 제공\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "]\n",
        "\n",
        "while True:\n",
        "    # 사용자로부터 메시지 입력 받기\n",
        "    message = input(\"User : \")\n",
        "\n",
        "    # 사용자가 'stop'이라고 입력하면 대화 종료\n",
        "    if message.lower() == \"stop\":\n",
        "        break\n",
        "    else:\n",
        "        # 사용자의 메시지를 메시지 목록에 추가\n",
        "        messages.append(\n",
        "             {\"role\": \"user\", \"content\": message}\n",
        "        )\n",
        "\n",
        "        # OpenAI API를 사용하여 대화형 완성 진행\n",
        "        completion = openai.chat.completions.create(\n",
        "          model=\"gpt-3.5-turbo\",\n",
        "          messages=messages\n",
        "        )\n",
        "\n",
        "    # 모델의 답변 추출\n",
        "    reply = completion.choices[0].message.content\n",
        "\n",
        "    # 모델의 답변 출력\n",
        "    print(f\"ChatGPT: {reply}\")\n",
        "\n",
        "    # 모델의 답변을 메시지 목록에 추가\n",
        "    messages.append({\"role\": \"assistant\", \"content\": reply})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e9d9105d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9d9105d",
        "outputId": "91684759-471b-489d-a170-33cf153a69c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'role': 'system', 'content': 'You are a helpful assistant.'},\n",
              " {'role': 'user', 'content': '안녕'},\n",
              " {'role': 'assistant', 'content': '안녕하세요! 도움이 필요하신가요?'},\n",
              " {'role': 'user', 'content': '서울역에서 남산에 가는 방법을 알려줘'},\n",
              " {'role': 'assistant',\n",
              "  'content': '서울역에서 남산에 가는 가장 간편한 방법은 지하철을 이용하는 것입니다. 아래는 세 가지의 경로 중 가장 흔히 사용되는 방법입니다:\\n\\n1. 지하철 4호선: 서울역에서 4호선으로 환승합니다. 시청역에서 1번 출구로 나와 남산으로 가는 계단을 찾아 올라가면 됩니다.\\n\\n2. 지하철 1호선: 서울역에서 1호선으로 환승합니다. 남영역에서 하차하여 저상버스 02 또는 03을 타고 남산도서관 정류장에서 내리면 됩니다.\\n\\n3. 지하철 2호선: 서울역에서 2호선으로 환승합니다. 시청역에서 1번 출구로 나와서 남산케이블카를 이용할 수도 있습니다. 혹은 시청역에서 도보로 10분 정도 걸어가면 남산에 도착합니다.\\n\\n여행하기 전에 대중교통 앱이나 웹사이트를 확인해 정확한 노선과 시간표를 확인하는 것이 좋습니다. 즐거운 시간 보내세요!'}]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "messages"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a589797d",
      "metadata": {
        "id": "a589797d"
      },
      "source": [
        "# Method 2 - API Endpoint 이용\n",
        "\n",
        "payload\"는 주로 HTTP 요청을 보낼 때 전달되는 데이터를 의미합니다. API 호출에서 \"payload\"는 주로 POST 요청의 본문에 포함된 데이터를 나타냅니다.  \n",
        "\n",
        "- temperature : 사용할 샘플링 온도는 0에서 2 사이입니다. 0.8과 같이 값이 높을수록 출력이 더 무작위로 생성(Hallucination 발생 가능)되고, 0.2와 같이 값이 낮을수록 더 집중적이고 결정적이게 됩니다.\n",
        "\n",
        "- top_p : temperature의 대안으로, 확률 top_p인 토큰의 결과를 고려합니다. 따라서 0.1은 상위 10% 확률을 구성하는 토큰만 고려된다는 의미입니다.\n",
        "\n",
        "**temperature 와 top_p 중 하나만 변경하고, 둘 다 변경하지는 않는 것이 좋습니다.**  \n",
        "\n",
        "- n:  각 입력 메시지에 대해 생성할 chat completion 선택 수입니다.  \n",
        "\n",
        "-  presence_penalty : -2.0과 2.0 사이의 숫자입니다. 양수 값은 지금까지 텍스트에 나타나는지 여부에 따라 새 토큰에 불이익을 주어 모델이 새로운 주제에 관해 이야기할 가능성을 높입니다.\n",
        "\n",
        "- frequency_penalty : -2.0과 2.0 사이의 숫자입니다. 양수 값은 지금까지 텍스트의 기존 빈도를 기반으로 새 토큰에 불이익을 주어 모델이 동일한 줄을 그대로 반복할 가능성을 줄입니다.  \n",
        "\n",
        "Bearer는 HTTP 인증 스키마 중 하나입니다. 웹 서비스에서 사용하는 토큰 기반의 인증 방식 중 가장 일반적인 방식입니다. Bearer를 사용하면, 클라이언트는 해당 토큰을 포함하여 서버에 요청을 보낼 수 있으며, 서버는 이 토큰을 검증하여 해당 클라이언트의 요청을 인증합니다. Bearer {토큰} 형식에서 {토큰} 부분은 실제 API를 사용하기 위한 인증 토큰을 나타냅니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2cb4c5b8",
      "metadata": {
        "id": "2cb4c5b8"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "# OpenAI API의 URL을 정의\n",
        "URL = \"https://api.openai.com/v1/chat/completions\"\n",
        "\n",
        "# 요청에 필요한 데이터를 payload 변수에 저장\n",
        "payload = {\n",
        "    \"model\": \"gpt-3.5-turbo\",\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": f\"세계 바둑 Champion이 누구야 ?\"}],\n",
        "    \"temperature\": 1.0,\n",
        "    \"top_p\": 1.0,\n",
        "    \"n\": 1,\n",
        "    \"stream\": False,     # 스트림모드 사용 여부\n",
        "    \"presence_penalty\": 0,  # 결과의 일관성에 영향\n",
        "    \"frequency_penalty\": 0,  # 단어의 사용 빈도에 영향\n",
        "}\n",
        "\n",
        "# 요청 헤더에 내용 유형 및 인증 키 설정\n",
        "headers = {\n",
        "    \"Content-Type\": \"application/json\",  # 요청 본문의 유형을 JSON으로 지정\n",
        "    \"Authorization\": f\"Bearer {openai.api_key}\"  # 인증 키 포함\n",
        "}\n",
        "\n",
        "# requests.post를 사용하여 OpenAI API에 POST 요청을 보냅니다.\n",
        "response = requests.post(URL, headers=headers, json=payload, stream=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "bfe7af8f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfe7af8f",
        "outputId": "c5f99bb9-638c-4f1e-cfbf-23bda982f292"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Response [200]>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0aa0d95d",
      "metadata": {
        "id": "0aa0d95d"
      },
      "source": [
        "### response 내용\n",
        "1. **choices**: API 응답의 주요 내용이 포함된 배열입니다.\n",
        "   - **finish_reason**: 응답이 완료된 이유입니다. 'stop'은 출력이 종료된 이유가 됩니다.\n",
        "   - **index**: 선택 사항의 인덱스 번호입니다.\n",
        "   - **message**: 사용자 또는 보조프로그램의 메시지 내용입니다.\n",
        "     - **content**: 보조프로그램이 생성한 메시지 내용입니다.\n",
        "     - **role**: 이 메시지를 생성한 주체입니다.  'assistant'는 메시지가 OpenAI의 assistena program으로부터 생성되었다는 것을 의미합니다.\n",
        "\n",
        "2. **created**: 응답이 생성된 시간의 타임스탬프입니다.\n",
        "\n",
        "3. **id**: 응답에 할당된 고유 식별자입니다.\n",
        "\n",
        "4. **model**: 사용된 모델의 이름입니다.\n",
        "\n",
        "5. **object**: 이 객체의 유형을 나타냅니다. 'chat.completion'은 채팅 완료 응답임을 나타냅니다.\n",
        "\n",
        "6. **usage**: 이 요청에서 사용된 토큰의 수를 나타내는 정보입니다.\n",
        "   - **completion_tokens**: 응답 내용에서 사용된 토큰 수입니다.\n",
        "   - **prompt_tokens**: 사용자의 원래 질문에서 사용된 토큰 수입니다.\n",
        "   - **total_tokens**: 전체 토큰 수입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "88f59c2f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88f59c2f",
        "outputId": "b0a111ed-64d4-45ad-a2cc-7ccaed26bac9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'choices': [{'finish_reason': 'stop',\n",
            "              'index': 0,\n",
            "              'logprobs': None,\n",
            "              'message': {'content': '현재 세계 바둑 챔피언은 중국의 Ke Jie입니다.',\n",
            "                          'role': 'assistant'}}],\n",
            " 'created': 1704863902,\n",
            " 'id': 'chatcmpl-8fLGoxohjMPNstu69AC2dTfWQNHuE',\n",
            " 'model': 'gpt-3.5-turbo-0613',\n",
            " 'object': 'chat.completion',\n",
            " 'system_fingerprint': None,\n",
            " 'usage': {'completion_tokens': 28, 'prompt_tokens': 22, 'total_tokens': 50}}\n"
          ]
        }
      ],
      "source": [
        "import pprint\n",
        "import json\n",
        "\n",
        "# 응답 내용을 JSON으로 파싱\n",
        "response_json = response.json()\n",
        "\n",
        "# 파싱된 JSON 내용을 pretty-print로 출력\n",
        "pprint.pprint(response_json)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "354fba90",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "354fba90",
        "outputId": "5a64c7f6-0605-4772-a0fd-725efb225a48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "현재 세계 바둑 챔피언은 중국의 Ke Jie입니다.\n"
          ]
        }
      ],
      "source": [
        "print(response_json['choices'][0]['message']['content'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6b0b2a4",
      "metadata": {
        "id": "a6b0b2a4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}